


<!DOCTYPE html>
<html id="htmlId">
<head>
  <meta http-equiv="Content-Type" content="text/html;charset=UTF-8"> 
  <title>Coverage Report > ArXivFetcher</title>
  <style type="text/css">
    @import "../../css/coverage.css";
    @import "../../css/idea.min.css";
  </style>
  <script type="text/javascript" src="../../js/highlight.min.js"></script>
  <script type="text/javascript" src="../../js/highlightjs-line-numbers.min.js"></script>
</head>

<body>
<div class="content">
<div class="breadCrumbs">
Current scope:     <a href="../../index.html">all classes</a>
    <span class="separator">|</span>
    <a href="../index.html">org.jabref.logic.importer.fetcher</a>
</div>

<h1>Coverage Summary for Class: ArXivFetcher (org.jabref.logic.importer.fetcher)</h1>

<table class="coverageStats">

<tr>
  <th class="name">Class</th>
<th class="coverageStat 
">
  Method, %
</th>
<th class="coverageStat 
">
  Branch, %
</th>
<th class="coverageStat 
">
  Line, %
</th>
</tr>
<tr>
  <td class="name">ArXivFetcher</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/25)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/20)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/80)
  </span>
</td>
</tr>
  <tr>
    <td class="name">ArXivFetcher$ArXiv</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/20)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/36)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/105)
  </span>
</td>
  </tr>
  <tr>
    <td class="name">ArXivFetcher$ArXiv$ArXivEntry</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/9)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/10)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/49)
  </span>
</td>
  </tr>
<tr>
  <td class="name"><strong>Total</strong></td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/54)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/66)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/234)
  </span>
</td>
</tr>
</table>

<br/>
<br/>


<pre>
<code class="sourceCode" id="sourceCode">&nbsp;package org.jabref.logic.importer.fetcher;
&nbsp;
&nbsp;import java.io.IOException;
&nbsp;import java.net.HttpURLConnection;
&nbsp;import java.net.MalformedURLException;
&nbsp;import java.net.URISyntaxException;
&nbsp;import java.net.URL;
&nbsp;import java.util.ArrayList;
&nbsp;import java.util.Collection;
&nbsp;import java.util.List;
&nbsp;import java.util.Map;
&nbsp;import java.util.Objects;
&nbsp;import java.util.Optional;
&nbsp;import java.util.Set;
&nbsp;import java.util.concurrent.CompletableFuture;
&nbsp;import java.util.concurrent.CompletionException;
&nbsp;import java.util.concurrent.ExecutorService;
&nbsp;import java.util.concurrent.Executors;
&nbsp;import java.util.stream.Collectors;
&nbsp;
&nbsp;import javax.xml.parsers.DocumentBuilder;
&nbsp;import javax.xml.parsers.DocumentBuilderFactory;
&nbsp;import javax.xml.parsers.ParserConfigurationException;
&nbsp;
&nbsp;import org.jabref.logic.cleanup.EprintCleanup;
&nbsp;import org.jabref.logic.help.HelpFile;
&nbsp;import org.jabref.logic.importer.FetcherException;
&nbsp;import org.jabref.logic.importer.FulltextFetcher;
&nbsp;import org.jabref.logic.importer.IdBasedFetcher;
&nbsp;import org.jabref.logic.importer.IdFetcher;
&nbsp;import org.jabref.logic.importer.ImportFormatPreferences;
&nbsp;import org.jabref.logic.importer.PagedSearchBasedFetcher;
&nbsp;import org.jabref.logic.importer.fetcher.transformers.ArXivQueryTransformer;
&nbsp;import org.jabref.logic.integrity.BracesCorrector;
&nbsp;import org.jabref.logic.util.URLUtil;
&nbsp;import org.jabref.logic.util.io.XMLUtil;
&nbsp;import org.jabref.logic.util.strings.StringSimilarity;
&nbsp;import org.jabref.model.entry.BibEntry;
&nbsp;import org.jabref.model.entry.KeywordList;
&nbsp;import org.jabref.model.entry.LinkedFile;
&nbsp;import org.jabref.model.entry.field.Field;
&nbsp;import org.jabref.model.entry.field.InternalField;
&nbsp;import org.jabref.model.entry.field.StandardField;
&nbsp;import org.jabref.model.entry.identifier.ArXivIdentifier;
&nbsp;import org.jabref.model.entry.identifier.DOI;
&nbsp;import org.jabref.model.entry.types.StandardEntryType;
&nbsp;import org.jabref.model.paging.Page;
&nbsp;import org.jabref.model.search.query.BaseQueryNode;
&nbsp;import org.jabref.model.strings.StringUtil;
&nbsp;import org.jabref.model.util.OptionalUtil;
&nbsp;
&nbsp;import org.apache.hc.core5.net.URIBuilder;
&nbsp;import org.slf4j.Logger;
&nbsp;import org.slf4j.LoggerFactory;
&nbsp;import org.w3c.dom.Document;
&nbsp;import org.w3c.dom.Node;
&nbsp;import org.xml.sax.SAXException;
&nbsp;
&nbsp;/**
&nbsp; * Fetcher for ArXiv that merges fields from arXiv-issued DOIs (and user-issued ones when applicable) to get more information overall.
&nbsp; * &lt;p&gt;
&nbsp; * These are the post-processing steps applied to the original fetch from ArXiv&#39;s API:
&nbsp; * &lt;ol&gt;
&nbsp; *     &lt;li&gt;Use ArXiv-issued DOI to get more merge more data with original entry, overwriting some of those fields;&lt;/li&gt;
&nbsp; *     &lt;li&gt;Use user-issued DOI (if it was provided) to merge even more data with the result of the previous step, overwriting some of those fields;&lt;/li&gt;
&nbsp; *     &lt;li&gt;Modify keywords: remove repetitions and adapt some edge cases (commas in keyword transformed into forward slashes).&lt;/li&gt;
&nbsp; * &lt;/ol&gt;
&nbsp; *
&nbsp; * @see &lt;a href=&quot;https://blog.arxiv.org/2022/02/17/new-arxiv-articles-are-now-automatically-assigned-dois/&quot;&gt;arXiv.org blog &lt;/a&gt; for more info about arXiv-issued DOIs
&nbsp; * @see &lt;a href=&quot;https://arxiv.org/help/api/index&quot;&gt;ArXiv API&lt;/a&gt; for an overview of the API
&nbsp; * @see &lt;a href=&quot;https://arxiv.org/help/api/user-manual#_calling_the_api&quot;&gt;ArXiv API User&#39;s Manual&lt;/a&gt; for a detailed description on how to use the API
&nbsp; */
&nbsp;public class ArXivFetcher implements FulltextFetcher, PagedSearchBasedFetcher, IdBasedFetcher, IdFetcher&lt;ArXivIdentifier&gt; {
&nbsp;
<b class="nc">&nbsp;    private static final Logger LOGGER = LoggerFactory.getLogger(ArXivFetcher.class);</b>
&nbsp;
&nbsp;    // See https://blog.arxiv.org/2022/02/17/new-arxiv-articles-are-now-automatically-assigned-dois/
&nbsp;    private static final String DOI_PREFIX = &quot;10.48550/arXiv.&quot;;
&nbsp;
&nbsp;    /*
&nbsp;     * Reason behind choice of these fields:
&nbsp;     *   - KEYWORDS: More descriptive
&nbsp;     *   - AUTHOR: Better formatted (last name, rest of name)
&nbsp;     */
<b class="nc">&nbsp;    private static final Set&lt;Field&gt; CHOSEN_AUTOMATIC_DOI_FIELDS = Set.of(StandardField.KEYWORDS, StandardField.AUTHOR);</b>
&nbsp;
&nbsp;    /*
&nbsp;     * Reason behind choice of these fields:
&nbsp;     *   - DOI: give preference to DOIs manually inputted by users, instead of automatic ones
&nbsp;     *   - PUBLISHER: ArXiv-issued DOIs give &#39;ArXiv&#39; as entry publisher. While this can be true, prefer using one from external sources,
&nbsp;     *      if applicable
&nbsp;     *   - KEY_FIELD: Usually, the KEY_FIELD retrieved from user-assigned DOIs are &#39;nicer&#39; (instead of a DOI link, it&#39;s usually contains one author and the year)
&nbsp;     */
<b class="nc">&nbsp;    private static final Set&lt;Field&gt; CHOSEN_MANUAL_DOI_FIELDS = Set.of(StandardField.DOI, StandardField.PUBLISHER, InternalField.KEY_FIELD);</b>
&nbsp;
<b class="nc">&nbsp;    private static final Map&lt;String, String&gt; ARXIV_KEYWORDS_WITH_COMMA_REPLACEMENTS = Map.of(</b>
&nbsp;            &quot;Computational Engineering, Finance, and Science&quot;, &quot;Computational Engineering / Finance / Science&quot;,
&nbsp;            &quot;Distributed, Parallel, and Cluster Computing&quot;, &quot;Distributed / Parallel / Cluster Computing&quot;);
&nbsp;
&nbsp;    private final ArXiv arXiv;
&nbsp;    private final DoiFetcher doiFetcher;
&nbsp;    private final ImportFormatPreferences importFormatPreferences;
&nbsp;
&nbsp;    public ArXivFetcher(ImportFormatPreferences importFormatPreferences) {
<b class="nc">&nbsp;        this(importFormatPreferences, new DoiFetcher(importFormatPreferences));</b>
&nbsp;    }
&nbsp;
&nbsp;    /**
&nbsp;     * @param doiFetcher The fetcher, maybe be NULL if no additional search is desired.
&nbsp;     */
<b class="nc">&nbsp;    public ArXivFetcher(ImportFormatPreferences importFormatPreferences, DoiFetcher doiFetcher) {</b>
<b class="nc">&nbsp;        this.arXiv = new ArXiv(importFormatPreferences);</b>
<b class="nc">&nbsp;        this.doiFetcher = doiFetcher;</b>
<b class="nc">&nbsp;        this.importFormatPreferences = importFormatPreferences;</b>
&nbsp;    }
&nbsp;
&nbsp;    @Override
&nbsp;    public Optional&lt;URL&gt; findFullText(BibEntry entry) throws IOException {
<b class="nc">&nbsp;        return arXiv.findFullText(entry);</b>
&nbsp;    }
&nbsp;
&nbsp;    @Override
&nbsp;    public TrustLevel getTrustLevel() {
<b class="nc">&nbsp;        return arXiv.getTrustLevel();</b>
&nbsp;    }
&nbsp;
&nbsp;    @Override
&nbsp;    public String getName() {
<b class="nc">&nbsp;        return arXiv.getName();</b>
&nbsp;    }
&nbsp;
&nbsp;    @Override
&nbsp;    public Optional&lt;HelpFile&gt; getHelpPage() {
<b class="nc">&nbsp;        return arXiv.getHelpPage();</b>
&nbsp;    }
&nbsp;
&nbsp;    /**
&nbsp;     * Remove duplicate values on &quot;KEYWORD&quot; field, if any. Al
&nbsp;     *
&nbsp;     * @param bibEntry A BibEntry to modify
&nbsp;     */
&nbsp;    private void adaptKeywordsFrom(BibEntry bibEntry) {
<b class="nc">&nbsp;        Optional&lt;String&gt; allKeywords = bibEntry.getField(StandardField.KEYWORDS);</b>
<b class="nc">&nbsp;        if (allKeywords.isPresent()) {</b>
&nbsp;            // With the use of ArXiv-issued DOI&#39;s KEYWORDS field, some of those keywords might contain comma. As this is the
&nbsp;            // default keyword separator, replace the commas of these instances with some other character
&nbsp;            // (see ARXIV_KEYWORDS_WITH_COMMA_REPLACEMENTS variable)
<b class="nc">&nbsp;            for (Map.Entry&lt;String, String&gt; entry : ARXIV_KEYWORDS_WITH_COMMA_REPLACEMENTS.entrySet()) {</b>
<b class="nc">&nbsp;                allKeywords = Optional.of(allKeywords.get().replaceAll(entry.getKey(), entry.getValue()));</b>
&nbsp;            }
&nbsp;
<b class="nc">&nbsp;            String filteredKeywords = KeywordList.merge(</b>
<b class="nc">&nbsp;                    allKeywords.get(),</b>
&nbsp;                    &quot;&quot;,
<b class="nc">&nbsp;                    importFormatPreferences.bibEntryPreferences().getKeywordSeparator()).toString();</b>
<b class="nc">&nbsp;            bibEntry.setField(StandardField.KEYWORDS, filteredKeywords);</b>
&nbsp;        }
&nbsp;    }
&nbsp;
&nbsp;    /**
&nbsp;     * Get ArXiv-issued DOI from the entry&#39;s arXiv ID
&nbsp;     * &lt;br/&gt;&lt;br/&gt;
&nbsp;     * ArXiv-issued DOIs are identifiers associated with every ArXiv entry. They are composed of a fixed
&nbsp;     * {@link #DOI_PREFIX} + the entry&#39;s ArXiv ID
&nbsp;     *
&nbsp;     * @param arXivId An ArXiv ID
&nbsp;     * @return ArXiv-issued DOI
&nbsp;     */
&nbsp;    private static String getAutomaticDoi(String arXivId) {
<b class="nc">&nbsp;        return DOI_PREFIX + arXivId;</b>
&nbsp;    }
&nbsp;
&nbsp;    /**
&nbsp;     * Get ArXiv-issued DOI from the arXiv entry itself.
&nbsp;     * &lt;br/&gt;&lt;br/&gt;
&nbsp;     * ArXiv-issued DOIs are identifiers associated with every ArXiv entry. They are composed of a fixed {@link #DOI_PREFIX} + the entry&#39;s ArXiv ID
&nbsp;     *
&nbsp;     * @param arXivBibEntry A Bibtex Entry, formatted as a ArXiv entry. Must contain an EPRINT field
&nbsp;     * @return ArXiv-issued DOI, or Empty, if method could not retrieve it
&nbsp;     */
&nbsp;    private static Optional&lt;String&gt; getAutomaticDoi(BibEntry arXivBibEntry) {
&nbsp;        // As the input should always contain a EPRINT if created from inner &#39;ArXiv&#39; class, don&#39;t bother doing a check that might call
&nbsp;        // ArXiv&#39;s API again (method &#39;findIdentifier&#39;)
<b class="nc">&nbsp;        Optional&lt;String&gt; entryEprint = arXivBibEntry.getField(StandardField.EPRINT);</b>
<b class="nc">&nbsp;        if (entryEprint.isEmpty()) {</b>
<b class="nc">&nbsp;            LOGGER.error(&quot;Cannot infer ArXiv-issued DOI from BibEntry: no &#39;EPRINT&#39; field found&quot;);</b>
<b class="nc">&nbsp;            return Optional.empty();</b>
&nbsp;        } else {
<b class="nc">&nbsp;            return Optional.of(ArXivFetcher.getAutomaticDoi(entryEprint.get()));</b>
&nbsp;        }
&nbsp;    }
&nbsp;
&nbsp;    /**
&nbsp;     * Get ArXiv-issued DOI from ArXiv Identifier object
&nbsp;     * &lt;br/&gt;&lt;br/&gt;
&nbsp;     * ArXiv-issued DOIs are identifiers associated with every ArXiv entry. They are composed of a fixed {@link #DOI_PREFIX} + the entry&#39;s ArXiv ID
&nbsp;     *
&nbsp;     * @param arXivId An ArXiv ID as internal object
&nbsp;     * @return ArXiv-issued DOI
&nbsp;     */
&nbsp;    private static String getAutomaticDoi(ArXivIdentifier arXivId) {
<b class="nc">&nbsp;        return getAutomaticDoi(arXivId.asStringWithoutVersion());</b>
&nbsp;    }
&nbsp;
&nbsp;    /**
&nbsp;     * Check if a specific DOI is user-assigned.
&nbsp;     */
&nbsp;    private static boolean isManualDoi(String doi) {
<b class="nc">&nbsp;        return !doi.toLowerCase().contains(DOI_PREFIX.toLowerCase());</b>
&nbsp;    }
&nbsp;
&nbsp;    /**
&nbsp;     * Get user-issued DOI from ArXiv Bibtex entry, if any
&nbsp;     * &lt;br/&gt;&lt;br/&gt;
&nbsp;     * User-issued DOIs are identifiers associated with some ArXiv entries that can associate an entry with an external service, like
&nbsp;     * &lt;a href=&quot;https://link.springer.com/&quot;&gt;Springer Link&lt;/a&gt;.
&nbsp;     *
&nbsp;     * @param arXivBibEntry An ArXiv Bibtex entry from where the DOI is extracted
&nbsp;     * @return User-issued DOI, if any field exists and if it&#39;s not an automatic one (see {@link #getAutomaticDoi(ArXivIdentifier)})
&nbsp;     */
&nbsp;    private static Optional&lt;String&gt; getManualDoi(BibEntry arXivBibEntry) {
<b class="nc">&nbsp;        return arXivBibEntry.getField(StandardField.DOI).filter(ArXivFetcher::isManualDoi);</b>
&nbsp;    }
&nbsp;
&nbsp;    /**
&nbsp;     * Get the Bibtex Entry from a Future API request (uses blocking) and treat exceptions.
&nbsp;     *
&nbsp;     * @param bibEntryFuture A CompletableFuture that parallelize the API fetching process
&nbsp;     * @return the fetch result
&nbsp;     */
&nbsp;    private static Optional&lt;BibEntry&gt; waitForBibEntryRetrieval(CompletableFuture&lt;Optional&lt;BibEntry&gt;&gt; bibEntryFuture) throws FetcherException {
&nbsp;        try {
<b class="nc">&nbsp;            return bibEntryFuture.join();</b>
&nbsp;        } catch (CompletionException e) {
<b class="nc">&nbsp;            if (!(e.getCause() instanceof FetcherException)) {</b>
<b class="nc">&nbsp;                LOGGER.error(&quot;The supplied future should only throw a FetcherException.&quot;, e);</b>
&nbsp;                throw e;
&nbsp;            }
<b class="nc">&nbsp;            throw (FetcherException) e.getCause();</b>
&nbsp;        }
&nbsp;    }
&nbsp;
&nbsp;    /**
&nbsp;     * Eventually merge the ArXiv Bibtex entry with a Future Bibtex entry (ArXiv/user-assigned DOIs)
&nbsp;     *
&nbsp;     * @param arXivEntry     The entry to merge into
&nbsp;     * @param bibEntryFuture A future result of the fetching process
&nbsp;     * @param priorityFields Which fields from &quot;bibEntryFuture&quot; to prioritize, replacing them on &quot;arXivEntry&quot;
&nbsp;     * @param id             Identifier used in initiating the &quot;bibEntryFuture&quot; future (for logging). This is usually a DOI, but can be anything.
&nbsp;     */
&nbsp;    private void mergeArXivEntryWithFutureDoiEntry(BibEntry arXivEntry, CompletableFuture&lt;Optional&lt;BibEntry&gt;&gt; bibEntryFuture, Set&lt;Field&gt; priorityFields, String id) {
&nbsp;        Optional&lt;BibEntry&gt; bibEntry;
&nbsp;        try {
<b class="nc">&nbsp;            bibEntry = waitForBibEntryRetrieval(bibEntryFuture);</b>
&nbsp;        } catch (FetcherException | CompletionException e) {
<b class="nc">&nbsp;            LOGGER.error(&quot;Failed to fetch future BibEntry with id &#39;{}&#39; (skipping merge).&quot;, id, e);</b>
&nbsp;            return;
&nbsp;        }
&nbsp;
<b class="nc">&nbsp;        if (bibEntry.isPresent()) {</b>
<b class="nc">&nbsp;            adaptKeywordsFrom(bibEntry.get());</b>
<b class="nc">&nbsp;            arXivEntry.mergeWith(bibEntry.get(), priorityFields);</b>
&nbsp;        } else {
<b class="nc">&nbsp;            LOGGER.error(&quot;Future BibEntry for id &#39;{}&#39; was completed, but no entry was found (skipping merge).&quot;, id);</b>
&nbsp;        }
&nbsp;    }
&nbsp;
&nbsp;    /**
&nbsp;     * Infuse arXivBibEntryPromise with additional fields in an asynchronous way
&nbsp;     *
&nbsp;     * @param arXivBibEntry An existing entry to be updated with new/modified fields
&nbsp;     */
&nbsp;    private void inplaceAsyncInfuseArXivWithDoi(BibEntry arXivBibEntry) {
<b class="nc">&nbsp;        CompletableFuture&lt;Optional&lt;BibEntry&gt;&gt; arXivBibEntryCompletedFuture = CompletableFuture.completedFuture(Optional.of(arXivBibEntry));</b>
<b class="nc">&nbsp;        Optional&lt;ArXivIdentifier&gt; arXivBibEntryId = arXivBibEntry.getField(StandardField.EPRINT).flatMap(ArXivIdentifier::parse);</b>
&nbsp;
&nbsp;        try {
<b class="nc">&nbsp;            this.inplaceAsyncInfuseArXivWithDoi(arXivBibEntryCompletedFuture, arXivBibEntryId);</b>
&nbsp;        } catch (FetcherException e) {
<b class="nc">&nbsp;            LOGGER.error(&quot;FetcherException should not be found here, as main Bibtex Entry already exists &quot; +</b>
&nbsp;                    &quot;(and failing additional fetches should be skipped)&quot;, e);
&nbsp;        }
&nbsp;    }
&nbsp;
&nbsp;    /**
&nbsp;     * Infuse arXivBibEntryFuture with additional fields in an asynchronous way, accelerating the process by providing a valid ArXiv ID
&nbsp;     *
&nbsp;     * @param arXivBibEntryFuture A future entry that (if it exists) will be updated with new/modified fields
&nbsp;     * @param arXivId             An ArXiv ID for the main reference (from ArXiv), so that the retrieval of ArXiv-issued DOI metadata can be faster
&nbsp;     * @throws FetcherException when failed to fetch the main ArtXiv Bibtex entry (&#39;arXivBibEntryFuture&#39;).
&nbsp;     */
&nbsp;    private void inplaceAsyncInfuseArXivWithDoi(CompletableFuture&lt;Optional&lt;BibEntry&gt;&gt; arXivBibEntryFuture, Optional&lt;ArXivIdentifier&gt; arXivId) throws FetcherException {
&nbsp;
&nbsp;        Optional&lt;CompletableFuture&lt;Optional&lt;BibEntry&gt;&gt;&gt; automaticDoiBibEntryFuture;
&nbsp;        Optional&lt;BibEntry&gt; arXivBibEntry;
&nbsp;
&nbsp;        Optional&lt;String&gt; automaticDoi;
&nbsp;        Optional&lt;String&gt; manualDoi;
&nbsp;
&nbsp;        // We can accelerate the processing time by initiating a parallel request for DOIFetcher with an ArXiv-issued DOI alongside the ArXiv fetching itself,
&nbsp;        // BUT ONLY IF we have a valid arXivId. If not, the ArXiv entry must be retrieved before, which invalidates this optimization (although we can still speed
&nbsp;        // up the process by running both the ArXiv-assigned and user-assigned DOI fetching at the same time, if an entry has this last information)
<b class="nc">&nbsp;        if (arXivId.isPresent()) {</b>
<b class="nc">&nbsp;            automaticDoi = Optional.of(ArXivFetcher.getAutomaticDoi(arXivId.get()));</b>
<b class="nc">&nbsp;            automaticDoiBibEntryFuture = Optional.of(doiFetcher.asyncPerformSearchById(automaticDoi.get()));</b>
&nbsp;
<b class="nc">&nbsp;            arXivBibEntry = ArXivFetcher.waitForBibEntryRetrieval(arXivBibEntryFuture);</b>
<b class="nc">&nbsp;            if (arXivBibEntry.isEmpty()) {</b>
&nbsp;                return;
&nbsp;            }
&nbsp;        } else {
&nbsp;            // If ArXiv fetch fails (FetcherException), exception must be passed onwards for the transparency of this class (original ArXiv fetcher does the same)
<b class="nc">&nbsp;            arXivBibEntry = ArXivFetcher.waitForBibEntryRetrieval(arXivBibEntryFuture);</b>
<b class="nc">&nbsp;            if (arXivBibEntry.isEmpty()) {</b>
&nbsp;                return;
&nbsp;            }
&nbsp;
<b class="nc">&nbsp;            automaticDoi = ArXivFetcher.getAutomaticDoi(arXivBibEntry.get());</b>
<b class="nc">&nbsp;            automaticDoiBibEntryFuture = automaticDoi.map(arXiv::asyncPerformSearchById);</b>
&nbsp;        }
&nbsp;
<b class="nc">&nbsp;        manualDoi = ArXivFetcher.getManualDoi(arXivBibEntry.get());</b>
<b class="nc">&nbsp;        Optional&lt;CompletableFuture&lt;Optional&lt;BibEntry&gt;&gt;&gt; manualDoiBibEntryFuture = manualDoi.map(doiFetcher::asyncPerformSearchById);</b>
&nbsp;
<b class="nc">&nbsp;        automaticDoiBibEntryFuture.ifPresent(future -&gt;</b>
<b class="nc">&nbsp;                mergeArXivEntryWithFutureDoiEntry(arXivBibEntry.get(), future, CHOSEN_AUTOMATIC_DOI_FIELDS, automaticDoi.get()));</b>
<b class="nc">&nbsp;        manualDoiBibEntryFuture.ifPresent(future -&gt;</b>
<b class="nc">&nbsp;                mergeArXivEntryWithFutureDoiEntry(arXivBibEntry.get(), future, CHOSEN_MANUAL_DOI_FIELDS, manualDoi.get()));</b>
&nbsp;    }
&nbsp;
&nbsp;    /**
&nbsp;     * Constructs a complex query string using the field prefixes specified at https://arxiv.org/help/api/user-manual
&nbsp;     * and modify resulting BibEntries with additional info from the ArXiv-issued DOI
&nbsp;     *
&nbsp;     * @param queryNode the first search query node
&nbsp;     * @return A list of entries matching the complex query
&nbsp;     */
&nbsp;    @Override
&nbsp;    public Page&lt;BibEntry&gt; performSearchPaged(BaseQueryNode queryNode, int pageNumber) throws FetcherException {
&nbsp;
<b class="nc">&nbsp;        Page&lt;BibEntry&gt; result = arXiv.performSearchPaged(queryNode, pageNumber);</b>
<b class="nc">&nbsp;        if (this.doiFetcher == null) {</b>
<b class="nc">&nbsp;            return result;</b>
&nbsp;        }
&nbsp;
<b class="nc">&nbsp;        ExecutorService executor = Executors.newFixedThreadPool(getPageSize() * 2);</b>
&nbsp;
<b class="nc">&nbsp;        Collection&lt;CompletableFuture&lt;BibEntry&gt;&gt; futureSearchResult = result.getContent()</b>
<b class="nc">&nbsp;                                                                           .stream()</b>
<b class="nc">&nbsp;                                                                           .map(bibEntry -&gt;</b>
<b class="nc">&nbsp;                                                                                   CompletableFuture.supplyAsync(() -&gt; {</b>
<b class="nc">&nbsp;                                                                                       this.inplaceAsyncInfuseArXivWithDoi(bibEntry);</b>
<b class="nc">&nbsp;                                                                                       return bibEntry;</b>
&nbsp;                                                                                   }, executor))
<b class="nc">&nbsp;                                                                           .toList();</b>
&nbsp;
<b class="nc">&nbsp;        Collection&lt;BibEntry&gt; modifiedSearchResult = futureSearchResult.stream()</b>
<b class="nc">&nbsp;                                                                      .map(CompletableFuture::join)</b>
<b class="nc">&nbsp;                                                                      .collect(Collectors.toList());</b>
&nbsp;
<b class="nc">&nbsp;        return new Page&lt;&gt;(result.getQuery(), result.getPageNumber(), modifiedSearchResult);</b>
&nbsp;    }
&nbsp;
&nbsp;    @Override
&nbsp;    public Optional&lt;BibEntry&gt; performSearchById(String identifier) throws FetcherException {
<b class="nc">&nbsp;        CompletableFuture&lt;Optional&lt;BibEntry&gt;&gt; arXivBibEntryPromise = arXiv.asyncPerformSearchById(identifier);</b>
<b class="nc">&nbsp;        if (this.doiFetcher != null) {</b>
<b class="nc">&nbsp;            inplaceAsyncInfuseArXivWithDoi(arXivBibEntryPromise, ArXivIdentifier.parse(identifier));</b>
&nbsp;        }
<b class="nc">&nbsp;        return arXivBibEntryPromise.join();</b>
&nbsp;    }
&nbsp;
&nbsp;    @Override
&nbsp;    public Optional&lt;ArXivIdentifier&gt; findIdentifier(BibEntry entry) throws FetcherException {
<b class="nc">&nbsp;        return arXiv.findIdentifier(entry);</b>
&nbsp;    }
&nbsp;
&nbsp;    @Override
&nbsp;    public String getIdentifierName() {
<b class="nc">&nbsp;        return arXiv.getIdentifierName();</b>
&nbsp;    }
&nbsp;
&nbsp;    /**
&nbsp;     * Fetcher for the arXiv.
&nbsp;     *
&nbsp;     * @see &lt;a href=&quot;https://arxiv.org/help/api/index&quot;&gt;ArXiv API&lt;/a&gt; for an overview of the API
&nbsp;     * @see &lt;a href=&quot;https://arxiv.org/help/api/user-manual#_calling_the_api&quot;&gt;ArXiv API User&#39;s Manual&lt;/a&gt; for a detailed
&nbsp;     * description on how to use the API
&nbsp;     * &lt;p&gt;
&nbsp;     * Similar implementions:
&nbsp;     * &lt;a href=&quot;https://github.com/nathangrigg/arxiv2bib&quot;&gt;arxiv2bib&lt;/a&gt; which is &lt;a href=&quot;https://arxiv2bibtex.org/&quot;&gt;live&lt;/a&gt;
&nbsp;     * &lt;a href=&quot;https://gitlab.c3sl.ufpr.br/portalmec/dspace-portalmec/blob/aa209d15082a9870f9daac42c78a35490ce77b52/dspace-api/src/main/java/org/dspace/submit/lookup/ArXivService.java&quot;&gt;dspace-portalmec&lt;/a&gt;
&nbsp;     */
&nbsp;    protected static class ArXiv implements FulltextFetcher, PagedSearchBasedFetcher, IdBasedFetcher, IdFetcher&lt;ArXivIdentifier&gt; {
&nbsp;
<b class="nc">&nbsp;        private static final Logger LOGGER = LoggerFactory.getLogger(ArXiv.class);</b>
&nbsp;
&nbsp;        private static final String API_URL = &quot;https://export.arxiv.org/api/query&quot;;
&nbsp;
<b class="nc">&nbsp;        private static final DocumentBuilderFactory DOCUMENT_BUILDER_FACTORY = DocumentBuilderFactory.newInstance();</b>
&nbsp;
&nbsp;        private final ImportFormatPreferences importFormatPreferences;
&nbsp;
<b class="nc">&nbsp;        public ArXiv(ImportFormatPreferences importFormatPreferences) {</b>
<b class="nc">&nbsp;            this.importFormatPreferences = importFormatPreferences;</b>
&nbsp;        }
&nbsp;
&nbsp;        @Override
&nbsp;        public Optional&lt;URL&gt; findFullText(BibEntry entry) throws IOException {
<b class="nc">&nbsp;            Objects.requireNonNull(entry);</b>
&nbsp;
&nbsp;            try {
<b class="nc">&nbsp;                Optional&lt;URL&gt; pdfUrl = searchForEntries(entry).stream()</b>
<b class="nc">&nbsp;                                                              .map(ArXivEntry::getPdfUrl)</b>
<b class="nc">&nbsp;                                                              .filter(Optional::isPresent)</b>
<b class="nc">&nbsp;                                                              .map(Optional::get)</b>
<b class="nc">&nbsp;                                                              .findFirst();</b>
<b class="nc">&nbsp;                pdfUrl.ifPresent(url -&gt; LOGGER.info(&quot;Fulltext PDF found @ arXiv.&quot;));</b>
<b class="nc">&nbsp;                return pdfUrl;</b>
&nbsp;            } catch (FetcherException e) {
<b class="nc">&nbsp;                LOGGER.warn(&quot;arXiv API request failed&quot;, e);</b>
&nbsp;            }
&nbsp;
<b class="nc">&nbsp;            return Optional.empty();</b>
&nbsp;        }
&nbsp;
&nbsp;        @Override
&nbsp;        public TrustLevel getTrustLevel() {
<b class="nc">&nbsp;            return TrustLevel.PREPRINT;</b>
&nbsp;        }
&nbsp;
&nbsp;        private Optional&lt;ArXivEntry&gt; searchForEntry(String searchQuery) throws FetcherException {
<b class="nc">&nbsp;            List&lt;ArXivEntry&gt; entries = queryApi(searchQuery, List.of(), 0, 1);</b>
<b class="nc">&nbsp;            if (entries.size() == 1) {</b>
<b class="nc">&nbsp;                return Optional.of(entries.getFirst());</b>
&nbsp;            } else {
<b class="nc">&nbsp;                return Optional.empty();</b>
&nbsp;            }
&nbsp;        }
&nbsp;
&nbsp;        private Optional&lt;ArXivEntry&gt; searchForEntryById(String id) throws FetcherException {
<b class="nc">&nbsp;            Optional&lt;ArXivIdentifier&gt; identifier = ArXivIdentifier.parse(id);</b>
<b class="nc">&nbsp;            if (identifier.isEmpty()) {</b>
<b class="nc">&nbsp;                return Optional.empty();</b>
&nbsp;            }
&nbsp;
<b class="nc">&nbsp;            List&lt;ArXivEntry&gt; entries = queryApi(&quot;&quot;, List.of(identifier.get()), 0, 1);</b>
<b class="nc">&nbsp;            if (!entries.isEmpty()) {</b>
<b class="nc">&nbsp;                return Optional.of(entries.getFirst());</b>
&nbsp;            } else {
<b class="nc">&nbsp;                return Optional.empty();</b>
&nbsp;            }
&nbsp;        }
&nbsp;
&nbsp;        private List&lt;ArXivEntry&gt; searchForEntries(BibEntry originalEntry) throws FetcherException {
&nbsp;            // We need to copy the entry, because we modify it by a cleanup job.
<b class="nc">&nbsp;            final BibEntry entry = new BibEntry(originalEntry);</b>
&nbsp;
&nbsp;            // 1. Check for Eprint
<b class="nc">&nbsp;            new EprintCleanup().cleanup(entry);</b>
<b class="nc">&nbsp;            Optional&lt;String&gt; identifier = entry.getField(StandardField.EPRINT);</b>
<b class="nc">&nbsp;            if (StringUtil.isNotBlank(identifier)) {</b>
&nbsp;                try {
&nbsp;                    // Get pdf of entry with the specified id
<b class="nc">&nbsp;                    return OptionalUtil.toList(searchForEntryById(identifier.get()));</b>
&nbsp;                } catch (FetcherException e) {
<b class="nc">&nbsp;                    LOGGER.warn(&quot;arXiv eprint API request failed&quot;, e);</b>
&nbsp;                }
&nbsp;            }
&nbsp;
&nbsp;            // 2. DOI and other fields
&nbsp;            String query;
<b class="nc">&nbsp;            Optional&lt;String&gt; doiString = entry.getField(StandardField.DOI)</b>
<b class="nc">&nbsp;                                              .flatMap(DOI::parse)</b>
<b class="nc">&nbsp;                                              .map(DOI::asString);</b>
&nbsp;
&nbsp;            // ArXiv-issued DOIs seem to be unsearchable from ArXiv API&#39;s &quot;query string&quot;, so ignore it
<b class="nc">&nbsp;            if (doiString.isPresent() &amp;&amp; ArXivFetcher.isManualDoi(doiString.get())) {</b>
<b class="nc">&nbsp;                query = &quot;doi:&quot; + doiString.get();</b>
&nbsp;            } else {
<b class="nc">&nbsp;                Optional&lt;String&gt; authorQuery = entry.getField(StandardField.AUTHOR).map(author -&gt; &quot;au:&quot; + author);</b>
<b class="nc">&nbsp;                Optional&lt;String&gt; titleQuery = entry.getField(StandardField.TITLE).map(title -&gt; &quot;ti:&quot; + StringUtil.ignoreCurlyBracket(title));</b>
<b class="nc">&nbsp;                query = String.join(&quot;+AND+&quot;, OptionalUtil.toList(authorQuery, titleQuery));</b>
&nbsp;            }
&nbsp;
<b class="nc">&nbsp;            Optional&lt;ArXivEntry&gt; arxivEntry = searchForEntry(query);</b>
<b class="nc">&nbsp;            if (arxivEntry.isPresent()) {</b>
&nbsp;                // Check if entry is a match
<b class="nc">&nbsp;                StringSimilarity match = new StringSimilarity();</b>
<b class="nc">&nbsp;                String arxivTitle = arxivEntry.get().title.orElse(&quot;&quot;);</b>
<b class="nc">&nbsp;                String entryTitle = StringUtil.ignoreCurlyBracket(entry.getField(StandardField.TITLE).orElse(&quot;&quot;));</b>
<b class="nc">&nbsp;                if (match.isSimilar(arxivTitle, entryTitle)) {</b>
<b class="nc">&nbsp;                    return OptionalUtil.toList(arxivEntry);</b>
&nbsp;                }
&nbsp;            }
&nbsp;
<b class="nc">&nbsp;            return List.of();</b>
&nbsp;        }
&nbsp;
&nbsp;        private List&lt;ArXivEntry&gt; searchForEntries(String searchQuery, int pageNumber) throws FetcherException {
<b class="nc">&nbsp;            return queryApi(searchQuery, List.of(), getPageSize() * pageNumber, getPageSize());</b>
&nbsp;        }
&nbsp;
&nbsp;        private List&lt;ArXivEntry&gt; queryApi(String searchQuery, List&lt;ArXivIdentifier&gt; ids, int start, int maxResults)
&nbsp;                throws FetcherException {
<b class="nc">&nbsp;            Document result = callApi(searchQuery, ids, start, maxResults);</b>
<b class="nc">&nbsp;            List&lt;Node&gt; entries = XMLUtil.asList(result.getElementsByTagName(&quot;entry&quot;));</b>
&nbsp;
<b class="nc">&nbsp;            return entries.stream().map(ArXivEntry::new).collect(Collectors.toList());</b>
&nbsp;        }
&nbsp;
&nbsp;        /**
&nbsp;         * Queries the API.
&nbsp;         * &lt;p&gt;
&nbsp;         * If only {@code searchQuery} is given, then the API will return results for each article that matches the query.
&nbsp;         * If only {@code ids} is given, then the API will return results for each article in the list.
&nbsp;         * If both {@code searchQuery} and {@code ids} are given, then the API will return each article in
&nbsp;         * {@code ids} that matches {@code searchQuery}. This allows the API to act as a results filter.
&nbsp;         *
&nbsp;         * @param searchQuery the search query used to find articles;
&nbsp;         *                    &lt;a href=&quot;http://arxiv.org/help/api/user-manual#query_details&quot;&gt;details&lt;/a&gt;
&nbsp;         * @param ids         a list of arXiv identifiers
&nbsp;         * @param start       the index of the first returned result (zero-based)
&nbsp;         * @param maxResults  the number of maximal results (has to be smaller than 2000)
&nbsp;         * @return the response from the API as a XML document (Atom 1.0)
&nbsp;         * @throws FetcherException if there was a problem while building the URL or the API was not accessible
&nbsp;         */
&nbsp;        private Document callApi(String searchQuery, List&lt;ArXivIdentifier&gt; ids, int start, int maxResults) throws FetcherException {
<b class="nc">&nbsp;            if (maxResults &gt; 2000) {</b>
<b class="nc">&nbsp;                throw new IllegalArgumentException(&quot;The arXiv API limits the number of maximal results to be 2000&quot;);</b>
&nbsp;            }
&nbsp;
&nbsp;            URIBuilder uriBuilder;
&nbsp;            try {
<b class="nc">&nbsp;                uriBuilder = new URIBuilder(API_URL);</b>
&nbsp;            } catch (URISyntaxException e) {
<b class="nc">&nbsp;                throw new FetcherException(&quot;Invalid URL&quot;, e);</b>
&nbsp;            }
&nbsp;            // The arXiv API has problems with accents, so we remove them (i.e. Fréchet -&gt; Frechet)
<b class="nc">&nbsp;            if (StringUtil.isNotBlank(searchQuery)) {</b>
<b class="nc">&nbsp;                uriBuilder.addParameter(&quot;search_query&quot;, StringUtil.stripAccents(searchQuery));</b>
&nbsp;            }
<b class="nc">&nbsp;            if (!ids.isEmpty()) {</b>
<b class="nc">&nbsp;                uriBuilder.addParameter(&quot;id_list&quot;,</b>
<b class="nc">&nbsp;                        ids.stream().map(ArXivIdentifier::asString).collect(Collectors.joining(&quot;,&quot;)));</b>
&nbsp;            }
<b class="nc">&nbsp;            uriBuilder.addParameter(&quot;start&quot;, String.valueOf(start));</b>
<b class="nc">&nbsp;            uriBuilder.addParameter(&quot;max_results&quot;, String.valueOf(maxResults));</b>
&nbsp;            URL url;
&nbsp;            try {
<b class="nc">&nbsp;                url = uriBuilder.build().toURL();</b>
&nbsp;            } catch (MalformedURLException | URISyntaxException e) {
<b class="nc">&nbsp;                throw new FetcherException(&quot;Invalid URL&quot;, e);</b>
&nbsp;            }
&nbsp;
&nbsp;            try {
<b class="nc">&nbsp;                DocumentBuilder builder = DOCUMENT_BUILDER_FACTORY.newDocumentBuilder();</b>
&nbsp;
<b class="nc">&nbsp;                HttpURLConnection connection = (HttpURLConnection) url.openConnection();</b>
<b class="nc">&nbsp;                if (connection.getResponseCode() == 400) {</b>
&nbsp;                    // Bad request error from server, try to get more information
<b class="nc">&nbsp;                    throw getException(builder.parse(connection.getErrorStream()));</b>
&nbsp;                } else {
<b class="nc">&nbsp;                    return builder.parse(connection.getInputStream());</b>
&nbsp;                }
&nbsp;            } catch (SAXException | ParserConfigurationException | IOException exception) {
<b class="nc">&nbsp;                throw new FetcherException(url, &quot;arXiv API request failed&quot;, exception);</b>
&nbsp;            }
&nbsp;        }
&nbsp;
&nbsp;        private FetcherException getException(Document error) {
<b class="nc">&nbsp;            List&lt;Node&gt; entries = XMLUtil.asList(error.getElementsByTagName(&quot;entry&quot;));</b>
&nbsp;
&nbsp;            // Check if the API returned an error
&nbsp;            // In case of an error, only one entry will be returned with the error information. For example:
&nbsp;            // https://export.arxiv.org/api/query?id_list=0307015
&nbsp;            // &lt;entry&gt;
&nbsp;            //      &lt;id&gt;https://arxiv.org/api/errors#incorrect_id_format_for_0307015&lt;/id&gt;
&nbsp;            //      &lt;title&gt;Error&lt;/title&gt;
&nbsp;            //      &lt;summary&gt;incorrect id format for 0307015&lt;/summary&gt;
&nbsp;            // &lt;/entry&gt;
<b class="nc">&nbsp;            if (entries.size() == 1) {</b>
<b class="nc">&nbsp;                Node node = entries.getFirst();</b>
<b class="nc">&nbsp;                Optional&lt;String&gt; id = XMLUtil.getNodeContent(node, &quot;id&quot;);</b>
<b class="nc">&nbsp;                Boolean isError = id.map(idContent -&gt; idContent.startsWith(&quot;http://arxiv.org/api/errors&quot;)).orElse(false);</b>
<b class="nc">&nbsp;                if (isError) {</b>
<b class="nc">&nbsp;                    String errorMessage = XMLUtil.getNodeContent(node, &quot;summary&quot;).orElse(&quot;Unknown error&quot;);</b>
<b class="nc">&nbsp;                    return new FetcherException(errorMessage);</b>
&nbsp;                }
&nbsp;            }
<b class="nc">&nbsp;            return new FetcherException(&quot;arXiv API request failed&quot;);</b>
&nbsp;        }
&nbsp;
&nbsp;        @Override
&nbsp;        public String getName() {
<b class="nc">&nbsp;            return &quot;ArXiv&quot;;</b>
&nbsp;        }
&nbsp;
&nbsp;        @Override
&nbsp;        public Optional&lt;HelpFile&gt; getHelpPage() {
<b class="nc">&nbsp;            return Optional.of(HelpFile.FETCHER_OAI2_ARXIV);</b>
&nbsp;        }
&nbsp;
&nbsp;        /**
&nbsp;         * Constructs a complex query string using the field prefixes specified at https://arxiv.org/help/api/user-manual
&nbsp;         *
&nbsp;         * @param queryNode the first search node
&nbsp;         * @return A list of entries matching the complex query
&nbsp;         */
&nbsp;        @Override
&nbsp;        public Page&lt;BibEntry&gt; performSearchPaged(BaseQueryNode queryNode, int pageNumber) throws FetcherException {
<b class="nc">&nbsp;            ArXivQueryTransformer transformer = new ArXivQueryTransformer();</b>
<b class="nc">&nbsp;            String transformedQuery = transformer.transformSearchQuery(queryNode).orElse(&quot;&quot;);</b>
<b class="nc">&nbsp;            List&lt;BibEntry&gt; searchResult = searchForEntries(transformedQuery, pageNumber)</b>
<b class="nc">&nbsp;                    .stream()</b>
<b class="nc">&nbsp;                    .map(arXivEntry -&gt; arXivEntry.toBibEntry(importFormatPreferences.bibEntryPreferences().getKeywordSeparator()))</b>
<b class="nc">&nbsp;                    .collect(Collectors.toList());</b>
&nbsp;
<b class="nc">&nbsp;            return new Page&lt;&gt;(transformedQuery, pageNumber, filterYears(searchResult, transformer));</b>
&nbsp;        }
&nbsp;
&nbsp;        private List&lt;BibEntry&gt; filterYears(List&lt;BibEntry&gt; searchResult, ArXivQueryTransformer transformer) {
<b class="nc">&nbsp;            return searchResult.stream()</b>
<b class="nc">&nbsp;                               .filter(entry -&gt; entry.getField(StandardField.DATE).isPresent())</b>
&nbsp;                               // Filter the date field for year only
<b class="nc">&nbsp;                               .filter(entry -&gt; transformer.getEndYear().isEmpty() || (Integer.parseInt(entry.getField(StandardField.DATE).get().substring(0, 4)) &lt;= transformer.getEndYear().get()))</b>
<b class="nc">&nbsp;                               .filter(entry -&gt; transformer.getStartYear().isEmpty() || (Integer.parseInt(entry.getField(StandardField.DATE).get().substring(0, 4)) &gt;= transformer.getStartYear().get()))</b>
<b class="nc">&nbsp;                               .collect(Collectors.toList());</b>
&nbsp;        }
&nbsp;
&nbsp;        protected CompletableFuture&lt;Optional&lt;BibEntry&gt;&gt; asyncPerformSearchById(String identifier) throws CompletionException {
<b class="nc">&nbsp;            return CompletableFuture.supplyAsync(() -&gt; {</b>
&nbsp;                try {
<b class="nc">&nbsp;                    return performSearchById(identifier);</b>
&nbsp;                } catch (FetcherException e) {
<b class="nc">&nbsp;                    throw new CompletionException(e);</b>
&nbsp;                }
&nbsp;            });
&nbsp;        }
&nbsp;
&nbsp;        @Override
&nbsp;        public Optional&lt;BibEntry&gt; performSearchById(String identifier) throws FetcherException {
<b class="nc">&nbsp;            return searchForEntryById(identifier)</b>
<b class="nc">&nbsp;                    .map(arXivEntry -&gt; arXivEntry.toBibEntry(importFormatPreferences.bibEntryPreferences().getKeywordSeparator()));</b>
&nbsp;        }
&nbsp;
&nbsp;        @Override
&nbsp;        public Optional&lt;ArXivIdentifier&gt; findIdentifier(BibEntry entry) throws FetcherException {
<b class="nc">&nbsp;            return searchForEntries(entry).stream()</b>
<b class="nc">&nbsp;                                          .map(ArXivEntry::getId)</b>
<b class="nc">&nbsp;                                          .filter(Optional::isPresent)</b>
<b class="nc">&nbsp;                                          .map(Optional::get)</b>
<b class="nc">&nbsp;                                          .findFirst();</b>
&nbsp;        }
&nbsp;
&nbsp;        @Override
&nbsp;        public String getIdentifierName() {
<b class="nc">&nbsp;            return &quot;ArXiv&quot;;</b>
&nbsp;        }
&nbsp;
&nbsp;        private static class ArXivEntry {
&nbsp;
&nbsp;            private final Optional&lt;String&gt; title;
&nbsp;            private final Optional&lt;String&gt; urlAbstractPage;
&nbsp;            private final Optional&lt;String&gt; publishedDate;
&nbsp;            private final Optional&lt;String&gt; abstractText;
&nbsp;            private final List&lt;String&gt; authorNames;
&nbsp;            private final List&lt;String&gt; categories;
&nbsp;            private final Optional&lt;URL&gt; pdfUrl;
&nbsp;            private final Optional&lt;String&gt; doi;
&nbsp;            private final Optional&lt;String&gt; journalReferenceText;
&nbsp;            private final Optional&lt;String&gt; primaryCategory;
&nbsp;
<b class="nc">&nbsp;            public ArXivEntry(Node item) {</b>
&nbsp;                // see https://arxiv.org/help/api/user-manual#_details_of_atom_results_returned
&nbsp;
&nbsp;                // Title of the article
&nbsp;                // The result from the arXiv contains hard line breaks, try to remove them
<b class="nc">&nbsp;                title = XMLUtil.getNodeContent(item, &quot;title&quot;).map(ArXivEntry::correctLineBreaks);</b>
&nbsp;
&nbsp;                // The url leading to the abstract page
<b class="nc">&nbsp;                urlAbstractPage = XMLUtil.getNodeContent(item, &quot;id&quot;);</b>
&nbsp;
&nbsp;                // Date on which the first version was published
<b class="nc">&nbsp;                publishedDate = XMLUtil.getNodeContent(item, &quot;published&quot;);</b>
&nbsp;
&nbsp;                // Abstract of the article
<b class="nc">&nbsp;                abstractText = XMLUtil.getNodeContent(item, &quot;summary&quot;).map(ArXivEntry::correctLineBreaks)</b>
<b class="nc">&nbsp;                                      .map(String::trim).map(BracesCorrector::apply);</b>
&nbsp;
&nbsp;                // Authors of the article
<b class="nc">&nbsp;                authorNames = new ArrayList&lt;&gt;();</b>
<b class="nc">&nbsp;                for (Node authorNode : XMLUtil.getNodesByName(item, &quot;author&quot;)) {</b>
<b class="nc">&nbsp;                    Optional&lt;String&gt; authorName = XMLUtil.getNodeContent(authorNode, &quot;name&quot;).map(String::trim);</b>
<b class="nc">&nbsp;                    authorName.ifPresent(authorNames::add);</b>
&nbsp;                }
&nbsp;
&nbsp;                // Categories (arXiv, ACM, or MSC classification)
<b class="nc">&nbsp;                categories = new ArrayList&lt;&gt;();</b>
<b class="nc">&nbsp;                for (Node categoryNode : XMLUtil.getNodesByName(item, &quot;category&quot;)) {</b>
<b class="nc">&nbsp;                    Optional&lt;String&gt; category = XMLUtil.getAttributeContent(categoryNode, &quot;term&quot;);</b>
<b class="nc">&nbsp;                    category.ifPresent(categories::add);</b>
&nbsp;                }
&nbsp;
&nbsp;                // Links
<b class="nc">&nbsp;                Optional&lt;URL&gt; pdfUrlParsed = Optional.empty();</b>
<b class="nc">&nbsp;                for (Node linkNode : XMLUtil.getNodesByName(item, &quot;link&quot;)) {</b>
<b class="nc">&nbsp;                    Optional&lt;String&gt; linkTitle = XMLUtil.getAttributeContent(linkNode, &quot;title&quot;);</b>
<b class="nc">&nbsp;                    if (linkTitle.equals(Optional.of(&quot;pdf&quot;))) {</b>
<b class="nc">&nbsp;                        pdfUrlParsed = XMLUtil.getAttributeContent(linkNode, &quot;href&quot;).map(url -&gt; {</b>
&nbsp;                            try {
<b class="nc">&nbsp;                                return URLUtil.create(url);</b>
&nbsp;                            } catch (MalformedURLException e) {
<b class="nc">&nbsp;                                return null;</b>
&nbsp;                            }
&nbsp;                        });
&nbsp;                    }
&nbsp;                }
<b class="nc">&nbsp;                pdfUrl = pdfUrlParsed;</b>
&nbsp;
&nbsp;                // Associated DOI
<b class="nc">&nbsp;                doi = XMLUtil.getNodeContent(item, &quot;arxiv:doi&quot;);</b>
&nbsp;
&nbsp;                // Journal reference (as provided by the author)
<b class="nc">&nbsp;                journalReferenceText = XMLUtil.getNodeContent(item, &quot;arxiv:journal_ref&quot;);</b>
&nbsp;
&nbsp;                // Primary category
&nbsp;                // Ex: &lt;arxiv:primary_category xmlns:arxiv=&quot;https://arxiv.org/schemas/atom&quot; term=&quot;math-ph&quot; scheme=&quot;http://arxiv.org/schemas/atom&quot;/&gt;
<b class="nc">&nbsp;                primaryCategory = XMLUtil.getNode(item, &quot;arxiv:primary_category&quot;)</b>
<b class="nc">&nbsp;                                         .flatMap(node -&gt; XMLUtil.getAttributeContent(node, &quot;term&quot;));</b>
&nbsp;            }
&nbsp;
&nbsp;            public static String correctLineBreaks(String s) {
<b class="nc">&nbsp;                String result = s.replaceAll(&quot;\\n(?!\\s*\\n)&quot;, &quot; &quot;);</b>
<b class="nc">&nbsp;                result = result.replaceAll(&quot;\\s*\\n\\s*&quot;, &quot;\n&quot;);</b>
<b class="nc">&nbsp;                return result.replaceAll(&quot; {2,}&quot;, &quot; &quot;).replaceAll(&quot;(^\\s*|\\s+$)&quot;, &quot;&quot;);</b>
&nbsp;            }
&nbsp;
&nbsp;            /**
&nbsp;             * Returns the url of the linked pdf
&nbsp;             */
&nbsp;            public Optional&lt;URL&gt; getPdfUrl() {
<b class="nc">&nbsp;                return pdfUrl;</b>
&nbsp;            }
&nbsp;
&nbsp;            /**
&nbsp;             * Returns the arXiv identifier
&nbsp;             */
&nbsp;            public Optional&lt;String&gt; getIdString() {
<b class="nc">&nbsp;                return urlAbstractPage.flatMap(ArXivIdentifier::parse).map(ArXivIdentifier::asStringWithoutVersion);</b>
&nbsp;            }
&nbsp;
&nbsp;            public Optional&lt;ArXivIdentifier&gt; getId() {
<b class="nc">&nbsp;                return getIdString().flatMap(ArXivIdentifier::parse);</b>
&nbsp;            }
&nbsp;
&nbsp;            /**
&nbsp;             * Returns the date when the first version was put on the arXiv
&nbsp;             */
&nbsp;            public Optional&lt;String&gt; getDate() {
&nbsp;                // Publication string also contains time, e.g. 2014-05-09T14:49:43Z
<b class="nc">&nbsp;                return publishedDate.map(date -&gt; {</b>
<b class="nc">&nbsp;                    if (date.length() &lt; 10) {</b>
<b class="nc">&nbsp;                        return null;</b>
&nbsp;                    } else {
<b class="nc">&nbsp;                        return date.substring(0, 10);</b>
&nbsp;                    }
&nbsp;                });
&nbsp;            }
&nbsp;
&nbsp;            public BibEntry toBibEntry(Character keywordDelimiter) {
<b class="nc">&nbsp;                BibEntry bibEntry = new BibEntry(StandardEntryType.Article);</b>
<b class="nc">&nbsp;                bibEntry.setField(StandardField.EPRINTTYPE, &quot;arXiv&quot;);</b>
<b class="nc">&nbsp;                bibEntry.setField(StandardField.AUTHOR, String.join(&quot; and &quot;, authorNames));</b>
<b class="nc">&nbsp;                bibEntry.addKeywords(categories, keywordDelimiter);</b>
<b class="nc">&nbsp;                getIdString().ifPresent(id -&gt; bibEntry.setField(StandardField.EPRINT, id));</b>
<b class="nc">&nbsp;                title.ifPresent(titleContent -&gt; bibEntry.setField(StandardField.TITLE, titleContent));</b>
<b class="nc">&nbsp;                doi.ifPresent(doiContent -&gt; bibEntry.setField(StandardField.DOI, doiContent));</b>
<b class="nc">&nbsp;                abstractText.ifPresent(abstractContent -&gt; bibEntry.setField(StandardField.ABSTRACT, abstractContent));</b>
<b class="nc">&nbsp;                getDate().ifPresent(date -&gt; bibEntry.setField(StandardField.DATE, date));</b>
<b class="nc">&nbsp;                primaryCategory.ifPresent(category -&gt; bibEntry.setField(StandardField.EPRINTCLASS, category));</b>
<b class="nc">&nbsp;                journalReferenceText.ifPresent(journal -&gt; bibEntry.setField(StandardField.JOURNAL, journal));</b>
<b class="nc">&nbsp;                getPdfUrl().ifPresent(url -&gt; bibEntry.setFiles(List.of(new LinkedFile(url, &quot;PDF&quot;))));</b>
<b class="nc">&nbsp;                return bibEntry;</b>
&nbsp;            }
&nbsp;        }
&nbsp;    }
&nbsp;}
</code>
</pre>
</div>

<script type="text/javascript">
(function() {
    var msie = false, msie9 = false;
    /*@cc_on
      msie = true;
      @if (@_jscript_version >= 9)
        msie9 = true;
      @end
    @*/

    if (!msie || msie && msie9) {
      hljs.highlightAll()
      hljs.initLineNumbersOnLoad();
    }
})();
</script>

<div class="footer">
    
    <div style="float:right;">generated on 2025-09-29 22:51</div>
</div>
</body>
</html>
