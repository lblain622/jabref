


<!DOCTYPE html>
<html id="htmlId">
<head>
  <meta http-equiv="Content-Type" content="text/html;charset=UTF-8"> 
  <title>Coverage Report > AiChatLogic</title>
  <style type="text/css">
    @import "../../css/coverage.css";
    @import "../../css/idea.min.css";
  </style>
  <script type="text/javascript" src="../../js/highlight.min.js"></script>
  <script type="text/javascript" src="../../js/highlightjs-line-numbers.min.js"></script>
</head>

<body>
<div class="content">
<div class="breadCrumbs">
Current scope:     <a href="../../index.html">all classes</a>
    <span class="separator">|</span>
    <a href="../index.html">org.jabref.logic.ai.chatting</a>
</div>

<h1>Coverage Summary for Class: AiChatLogic (org.jabref.logic.ai.chatting)</h1>

<table class="coverageStats">
<tr>
  <th class="name">Class</th>
<th class="coverageStat 
">
  Class, %
</th>
<th class="coverageStat 
">
  Method, %
</th>
<th class="coverageStat 
">
  Branch, %
</th>
<th class="coverageStat 
">
  Line, %
</th>
</tr>
<tr>
  <td class="name">AiChatLogic</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/1)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/12)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/4)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/78)
  </span>
</td>
</tr>

</table>

<br/>
<br/>


<pre>
<code class="sourceCode" id="sourceCode">&nbsp;package org.jabref.logic.ai.chatting;
&nbsp;
&nbsp;import java.util.List;
&nbsp;import java.util.Optional;
&nbsp;
&nbsp;import javafx.beans.property.StringProperty;
&nbsp;import javafx.collections.ListChangeListener;
&nbsp;import javafx.collections.ObservableList;
&nbsp;
&nbsp;import org.jabref.logic.ai.AiPreferences;
&nbsp;import org.jabref.logic.ai.ingestion.FileEmbeddingsManager;
&nbsp;import org.jabref.logic.ai.templates.AiTemplate;
&nbsp;import org.jabref.logic.ai.templates.AiTemplatesService;
&nbsp;import org.jabref.logic.ai.templates.PaperExcerpt;
&nbsp;import org.jabref.logic.ai.util.ErrorMessage;
&nbsp;import org.jabref.model.database.BibDatabaseContext;
&nbsp;import org.jabref.model.entry.BibEntry;
&nbsp;import org.jabref.model.entry.LinkedFile;
&nbsp;import org.jabref.model.util.ListUtil;
&nbsp;
&nbsp;import dev.langchain4j.data.message.AiMessage;
&nbsp;import dev.langchain4j.data.message.ChatMessage;
&nbsp;import dev.langchain4j.data.message.SystemMessage;
&nbsp;import dev.langchain4j.data.message.UserMessage;
&nbsp;import dev.langchain4j.data.segment.TextSegment;
&nbsp;import dev.langchain4j.memory.ChatMemory;
&nbsp;import dev.langchain4j.memory.chat.TokenWindowChatMemory;
&nbsp;import dev.langchain4j.model.chat.ChatModel;
&nbsp;import dev.langchain4j.model.embedding.EmbeddingModel;
&nbsp;import dev.langchain4j.model.openai.OpenAiChatModelName;
&nbsp;import dev.langchain4j.model.openai.OpenAiTokenCountEstimator;
&nbsp;import dev.langchain4j.store.embedding.EmbeddingMatch;
&nbsp;import dev.langchain4j.store.embedding.EmbeddingSearchRequest;
&nbsp;import dev.langchain4j.store.embedding.EmbeddingSearchResult;
&nbsp;import dev.langchain4j.store.embedding.EmbeddingStore;
&nbsp;import dev.langchain4j.store.embedding.filter.Filter;
&nbsp;import dev.langchain4j.store.embedding.filter.MetadataFilterBuilder;
&nbsp;import org.slf4j.Logger;
&nbsp;import org.slf4j.LoggerFactory;
&nbsp;
&nbsp;public class AiChatLogic {
<b class="nc">&nbsp;    private static final Logger LOGGER = LoggerFactory.getLogger(AiChatLogic.class);</b>
&nbsp;
&nbsp;    private final AiPreferences aiPreferences;
&nbsp;    private final ChatModel chatLanguageModel;
&nbsp;    private final EmbeddingModel embeddingModel;
&nbsp;    private final EmbeddingStore&lt;TextSegment&gt; embeddingStore;
&nbsp;    private final AiTemplatesService aiTemplatesService;
&nbsp;
&nbsp;    private final ObservableList&lt;ChatMessage&gt; chatHistory;
&nbsp;    private final ObservableList&lt;BibEntry&gt; entries;
&nbsp;    private final StringProperty name;
&nbsp;    private final BibDatabaseContext bibDatabaseContext;
&nbsp;
&nbsp;    private ChatMemory chatMemory;
&nbsp;
<b class="nc">&nbsp;    private Optional&lt;Filter&gt; filter = Optional.empty();</b>
&nbsp;
&nbsp;    public AiChatLogic(AiPreferences aiPreferences,
&nbsp;                       ChatModel chatLanguageModel,
&nbsp;                       EmbeddingModel embeddingModel,
&nbsp;                       EmbeddingStore&lt;TextSegment&gt; embeddingStore,
&nbsp;                       AiTemplatesService aiTemplatesService,
&nbsp;                       StringProperty name,
&nbsp;                       ObservableList&lt;ChatMessage&gt; chatHistory,
&nbsp;                       ObservableList&lt;BibEntry&gt; entries,
&nbsp;                       BibDatabaseContext bibDatabaseContext
<b class="nc">&nbsp;    ) {</b>
<b class="nc">&nbsp;        this.aiPreferences = aiPreferences;</b>
<b class="nc">&nbsp;        this.chatLanguageModel = chatLanguageModel;</b>
<b class="nc">&nbsp;        this.embeddingModel = embeddingModel;</b>
<b class="nc">&nbsp;        this.embeddingStore = embeddingStore;</b>
<b class="nc">&nbsp;        this.aiTemplatesService = aiTemplatesService;</b>
<b class="nc">&nbsp;        this.chatHistory = chatHistory;</b>
<b class="nc">&nbsp;        this.entries = entries;</b>
<b class="nc">&nbsp;        this.name = name;</b>
<b class="nc">&nbsp;        this.bibDatabaseContext = bibDatabaseContext;</b>
&nbsp;
<b class="nc">&nbsp;        this.entries.addListener((ListChangeListener&lt;BibEntry&gt;) change -&gt; rebuildFilter());</b>
&nbsp;
<b class="nc">&nbsp;        setupListeningToPreferencesChanges();</b>
<b class="nc">&nbsp;        rebuildFull(chatHistory);</b>
&nbsp;    }
&nbsp;
&nbsp;    private void setupListeningToPreferencesChanges() {
<b class="nc">&nbsp;        aiPreferences</b>
<b class="nc">&nbsp;                .templateProperty(AiTemplate.CHATTING_SYSTEM_MESSAGE)</b>
<b class="nc">&nbsp;                .addListener(obs -&gt;</b>
<b class="nc">&nbsp;                        setSystemMessage(aiTemplatesService.makeChattingSystemMessage(entries)));</b>
&nbsp;
<b class="nc">&nbsp;        aiPreferences.contextWindowSizeProperty().addListener(obs -&gt; rebuildFull(chatMemory.messages()));</b>
&nbsp;    }
&nbsp;
&nbsp;    private void rebuildFull(List&lt;ChatMessage&gt; chatMessages) {
<b class="nc">&nbsp;        rebuildChatMemory(chatMessages);</b>
<b class="nc">&nbsp;        rebuildFilter();</b>
&nbsp;    }
&nbsp;
&nbsp;    private void rebuildChatMemory(List&lt;ChatMessage&gt; chatMessages) {
&nbsp;        // Because we can&#39;t get a tokenizer for each model, {@link AiChatLogic} assumes that
&nbsp;        // every text is tokenized like it&#39;s tokenized for OpenAI&#39;s GPT-4o-mini model.
&nbsp;        //
&nbsp;        // Reasons why we can&#39;t get tokenizer for each model:
&nbsp;        // - Some tokenizers might not be available in langchain4j.
&nbsp;        // - User may use a custom model, but there is no way to supply a custom tokenizer.
&nbsp;        // - OpenAI API (and compatible ones) doesn&#39;t have an endpoint for tokenizing text.
&nbsp;        //
&nbsp;        // This is another dark workaround of AI integration. But it works &quot;good-enough&quot; for now.
<b class="nc">&nbsp;        this.chatMemory = TokenWindowChatMemory</b>
<b class="nc">&nbsp;                .builder()</b>
<b class="nc">&nbsp;                .maxTokens(aiPreferences.getContextWindowSize(), new OpenAiTokenCountEstimator(OpenAiChatModelName.GPT_4_O_MINI))</b>
<b class="nc">&nbsp;                .build();</b>
&nbsp;
<b class="nc">&nbsp;        chatMessages.stream().filter(chatMessage -&gt; !(chatMessage instanceof ErrorMessage)).forEach(chatMemory::add);</b>
&nbsp;
<b class="nc">&nbsp;        setSystemMessage(aiTemplatesService.makeChattingSystemMessage(entries));</b>
&nbsp;    }
&nbsp;
&nbsp;    private void rebuildFilter() {
<b class="nc">&nbsp;        List&lt;LinkedFile&gt; linkedFiles = ListUtil.getLinkedFiles(entries).toList();</b>
&nbsp;
<b class="nc">&nbsp;        if (linkedFiles.isEmpty()) {</b>
<b class="nc">&nbsp;            filter = Optional.empty();</b>
&nbsp;        } else {
<b class="nc">&nbsp;            filter = Optional.of(MetadataFilterBuilder</b>
<b class="nc">&nbsp;                    .metadataKey(FileEmbeddingsManager.LINK_METADATA_KEY)</b>
<b class="nc">&nbsp;                    .isIn(linkedFiles</b>
<b class="nc">&nbsp;                            .stream()</b>
<b class="nc">&nbsp;                            .map(LinkedFile::getLink)</b>
<b class="nc">&nbsp;                            .toList()</b>
&nbsp;                    ));
&nbsp;        }
&nbsp;    }
&nbsp;
&nbsp;    private void setSystemMessage(String systemMessage) {
<b class="nc">&nbsp;        chatMemory.add(new SystemMessage(systemMessage));</b>
&nbsp;    }
&nbsp;
&nbsp;    public AiMessage execute(UserMessage message) {
&nbsp;        // Message will be automatically added to ChatMemory through ConversationalRetrievalChain.
&nbsp;
<b class="nc">&nbsp;        chatHistory.add(message);</b>
&nbsp;
<b class="nc">&nbsp;        LOGGER.info(&quot;Sending message to AI provider ({}) for answering in {}: {}&quot;,</b>
<b class="nc">&nbsp;                aiPreferences.getAiProvider().getApiUrl(),</b>
<b class="nc">&nbsp;                name.get(),</b>
<b class="nc">&nbsp;                message.singleText());</b>
&nbsp;
&nbsp;        EmbeddingSearchRequest embeddingSearchRequest = EmbeddingSearchRequest
<b class="nc">&nbsp;                .builder()</b>
<b class="nc">&nbsp;                .maxResults(aiPreferences.getRagMaxResultsCount())</b>
<b class="nc">&nbsp;                .minScore(aiPreferences.getRagMinScore())</b>
<b class="nc">&nbsp;                .filter(filter.orElse(null))</b>
<b class="nc">&nbsp;                .queryEmbedding(embeddingModel.embed(message.singleText()).content())</b>
<b class="nc">&nbsp;                .build();</b>
&nbsp;
<b class="nc">&nbsp;        EmbeddingSearchResult&lt;TextSegment&gt; embeddingSearchResult = embeddingStore.search(embeddingSearchRequest);</b>
&nbsp;
<b class="nc">&nbsp;        List&lt;PaperExcerpt&gt; excerpts = embeddingSearchResult</b>
<b class="nc">&nbsp;                .matches()</b>
<b class="nc">&nbsp;                .stream()</b>
<b class="nc">&nbsp;                .map(EmbeddingMatch::embedded)</b>
<b class="nc">&nbsp;                .map(textSegment -&gt; {</b>
<b class="nc">&nbsp;                    String link = textSegment.metadata().getString(FileEmbeddingsManager.LINK_METADATA_KEY);</b>
&nbsp;
<b class="nc">&nbsp;                    if (link == null) {</b>
<b class="nc">&nbsp;                        return new PaperExcerpt(&quot;&quot;, textSegment.text());</b>
&nbsp;                    } else {
<b class="nc">&nbsp;                        return new PaperExcerpt(findEntryByLink(link).flatMap(BibEntry::getCitationKey).orElse(&quot;&quot;), textSegment.text());</b>
&nbsp;                    }
&nbsp;                })
<b class="nc">&nbsp;                .toList();</b>
&nbsp;
<b class="nc">&nbsp;        LOGGER.debug(&quot;Found excerpts for the message: {}&quot;, excerpts);</b>
&nbsp;
&nbsp;        // This is crazy, but langchain4j {@link ChatMemory} does not allow to remove single messages.
&nbsp;        ChatMemory tempChatMemory = TokenWindowChatMemory
<b class="nc">&nbsp;                .builder()</b>
<b class="nc">&nbsp;                .maxTokens(aiPreferences.getContextWindowSize(), new OpenAiTokenCountEstimator(OpenAiChatModelName.GPT_4_O_MINI))</b>
<b class="nc">&nbsp;                .build();</b>
&nbsp;
<b class="nc">&nbsp;        chatMemory.messages().forEach(tempChatMemory::add);</b>
&nbsp;
<b class="nc">&nbsp;        tempChatMemory.add(new UserMessage(aiTemplatesService.makeChattingUserMessage(entries, message.singleText(), excerpts)));</b>
<b class="nc">&nbsp;        chatMemory.add(message);</b>
&nbsp;
<b class="nc">&nbsp;        AiMessage aiMessage = chatLanguageModel.chat(tempChatMemory.messages()).aiMessage();</b>
&nbsp;
<b class="nc">&nbsp;        chatMemory.add(aiMessage);</b>
<b class="nc">&nbsp;        chatHistory.add(aiMessage);</b>
&nbsp;
<b class="nc">&nbsp;        LOGGER.debug(&quot;Message was answered by the AI provider for {}: {}&quot;, name.get(), aiMessage.text());</b>
&nbsp;
<b class="nc">&nbsp;        return aiMessage;</b>
&nbsp;    }
&nbsp;
&nbsp;    private Optional&lt;BibEntry&gt; findEntryByLink(String link) {
<b class="nc">&nbsp;        return bibDatabaseContext</b>
<b class="nc">&nbsp;                .getEntries()</b>
<b class="nc">&nbsp;                .stream()</b>
<b class="nc">&nbsp;                .filter(entry -&gt; entry.getFiles().stream().anyMatch(file -&gt; file.getLink().equals(link)))</b>
<b class="nc">&nbsp;                .findFirst();</b>
&nbsp;    }
&nbsp;
&nbsp;    public ObservableList&lt;ChatMessage&gt; getChatHistory() {
<b class="nc">&nbsp;        return chatHistory;</b>
&nbsp;    }
&nbsp;}
</code>
</pre>
</div>

<script type="text/javascript">
(function() {
    var msie = false, msie9 = false;
    /*@cc_on
      msie = true;
      @if (@_jscript_version >= 9)
        msie9 = true;
      @end
    @*/

    if (!msie || msie && msie9) {
      hljs.highlightAll()
      hljs.initLineNumbersOnLoad();
    }
})();
</script>

<div class="footer">
    
    <div style="float:right;">generated on 2025-09-29 22:51</div>
</div>
</body>
</html>
